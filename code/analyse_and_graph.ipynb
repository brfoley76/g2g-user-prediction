{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model, model_selection, feature_extraction, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2GDat():\n",
    "    '''\n",
    "    Read in the scraped data, and prepare it for analysis.\n",
    "    '''\n",
    "    def __init__(self, user_file, question_file):\n",
    "        with open(user_file) as json_data:\n",
    "            self.Users = json.load(json_data)\n",
    "            \n",
    "        with open(question_file) as json_data:\n",
    "            self.Questions = json.load(json_data)\n",
    "            \n",
    "            \n",
    "    def peek(self, dictName):\n",
    "        '''\n",
    "        Look at a single item in a dictionary\n",
    "        '''\n",
    "        outDict = {}\n",
    "        if dictName == 'users':\n",
    "            key, val = self.Users.iteritems().next()\n",
    "            outDict[deepcopy(key)]=deepcopy(val)\n",
    "            return outDict\n",
    "        elif dictName == 'questions':\n",
    "            key, val = self.Questions.iteritems().next()\n",
    "            outDict[deepcopy(key)] = deepcopy(val)\n",
    "            return outDict        \n",
    "        else:\n",
    "            return 'I don\\'t know how to do that.'\n",
    "                \n",
    "         \n",
    "    def flattenQuestions(self):\n",
    "        '''\n",
    "        extract mean sentiment, and n-measures\n",
    "        '''\n",
    "        for quest,content in self.Questions.iteritems():\n",
    "            try:\n",
    "                summed_sent = sum(content['stats']['tone'])\n",
    "                count = len(content['stats']['tone'])\n",
    "                if count == 0:\n",
    "                    summed_sent = 0.\n",
    "                    mean_sent = 0.\n",
    "                else:\n",
    "                    mean_sent = summed_sent/float(count)\n",
    "                self.Questions[quest]['stats']['summed_sent'] = summed_sent\n",
    "                self.Questions[quest]['stats']['mean_sent'] = mean_sent\n",
    "            except:\n",
    "                self.Questions[quest]['stats'] = {'summed_sent':0., 'mean_sent':0., 'count':0}\n",
    "            \n",
    "\n",
    "    def calcUserPerQuestion(self):\n",
    "        '''\n",
    "        extract summed sentiment contribution per question for each user\n",
    "        '''\n",
    "        for user, uservals in self.Users.iteritems():\n",
    "            questDict = {}\n",
    "            i = 0\n",
    "            for quest in uservals['questionIds']:\n",
    "                if not quest in questDict:\n",
    "                    questDict[quest]={'count':0., 'summed':0.}\n",
    "                questDict[quest]['count'] += 1.\n",
    "                questDict[quest]['summed'] += uservals['textSent'][i]\n",
    "                i += 1\n",
    "            self.Users[user]['questDict'] = questDict\n",
    "\n",
    "\n",
    "    def calcUserResidual(self):\n",
    "        '''\n",
    "        extract user_deviation from question tone\n",
    "        mean user-corrected question sentiment, and\n",
    "        '''\n",
    "        for user, uservals in self.Users.iteritems():\n",
    "            u_n_vals = []\n",
    "            u_sum_vals = []\n",
    "            q_n_vals = []\n",
    "            q_sum_vals = []\n",
    "            for quest, val in uservals['questDict'].iteritems():\n",
    "                u_n_vals += [(val['count'] + 0.)]\n",
    "                u_sum_vals += [(val['summed'] + 0.)]\n",
    "                questionData = self.Questions[quest]['stats']\n",
    "                q_n_vals += [(questionData['count'] + 0.)]\n",
    "                q_sum_vals += [(questionData['summed_sent'] + 0.)]\n",
    "            #should be weighted by n-measures?\n",
    "            #but will weight all qs the same, no matter how many utterances.\n",
    "            #u_n_vals = [(1. if x < 1. else x) for x in u_n_vals]\n",
    "            u_sent_means = np.divide(u_sum_vals, u_n_vals)\n",
    "            q_corrected_n = np.asarray(q_n_vals) - np.asarray(u_n_vals)\n",
    "            q_corrected_n[q_corrected_n < 1] = 1.\n",
    "            q_corrected_sum = np.asarray(q_sum_vals) - np.asarray(u_sum_vals)\n",
    "            q_corrected_means = np.divide(q_corrected_sum, q_corrected_n)\n",
    "            u_delt_sent = u_sent_means - q_corrected_means\n",
    "            mean_delt_sent = np.mean(u_delt_sent)\n",
    "            mean_q_corrected = np.mean(q_corrected_means)\n",
    "            self.Users[user]['mean_delt_sent'] = mean_delt_sent\n",
    "            self.Users[user]['mean_q_corrected'] = mean_q_corrected\n",
    "            self.Users[user]['mean_sent'] = np.mean(u_sent_means)\n",
    "            ####################\n",
    "            ## now do log-ratios\n",
    "            n_texts = np.sum(u_n_vals)\n",
    "            self.Users[user]['n_texts'] = n_texts\n",
    "            trans_sent = (mean_delt_sent + 1.15) / 2.15 # min 0\n",
    "            trans_sent = trans_sent * (n_texts / (1. + n_texts)) # correct for the number of texts\n",
    "            self.Users[user]['trans_delt_sent'] = np.log(trans_sent / (1. - trans_sent))\n",
    "            trans_q_adjust = (mean_q_corrected + 1.) / 2.\n",
    "            trans_q_adjust = trans_q_adjust * (n_texts / (1. + n_texts))\n",
    "            self.Users[user]['trans_q_adjust'] = np.log(trans_q_adjust / (1. - trans_q_adjust))\n",
    "        \n",
    "    def calcEvokedFeelings(self):\n",
    "        '''\n",
    "        Go through the questions, extract summed sentiment, and n-measures\n",
    "        Go through the users, count per-question-input-number, and per-question-mean-sentiment \n",
    "            and also per-question-sentiment not counting the users' input.\n",
    "        '''\n",
    "        self.flattenQuestions()\n",
    "        self.calcUserPerQuestion()\n",
    "        self.calcUserResidual() \n",
    "\n",
    "        \n",
    "    def convertG2Gcsv(self):\n",
    "        '''\n",
    "        process the syllable data and stuff to be simple metrics\n",
    "        then convert to csv and save.\n",
    "        '''\n",
    "        q_data = self.Questions.copy()\n",
    "        data = self.Users.copy()\n",
    "        \n",
    "        for key, value in q_data.iteritems():\n",
    "            try:\n",
    "                tone_list = value['stats'].pop('tone', None)\n",
    "                mean_tone = np.mean(tone_list)\n",
    "                value['mean_tone'] = mean_tone\n",
    "                value['count'] = tone_list=value['stats'].pop('count', None)\n",
    "            except:\n",
    "                print key\n",
    "\n",
    "        for key, value in data.iteritems():\n",
    "            nSylls = np.array(value.pop('nSylls', None))\n",
    "            textLen = np.array(value.pop('textLens', None))\n",
    "            textLen = textLen+0.\n",
    "            textSent = np.array(value.pop('textSent', None))\n",
    "\n",
    "            textDay = str(value.pop('day', None))\n",
    "            textMon = str(value.pop('mon', None))\n",
    "            textYear = str(value.pop('year', None))\n",
    "            date = textDay + ' ' + textMon + ' ' + textYear\n",
    "            start_date = (datetime.now() - datetime.strptime(date, '%d %b %Y')).days\n",
    "            value['start_date'] = start_date\n",
    "            \n",
    "            textDays = value.pop('days', None)\n",
    "            textDays.sort(reverse=False)  \n",
    "            textSum = np.sum(textLen)\n",
    "            \n",
    "            qD=value.pop('questDict', None)\n",
    "            qID=value.pop('questionIds', None)\n",
    "            value['contributions'] = float(value['contributions'].replace(',', ''))\n",
    "            nTexts= value['n_texts']\n",
    "            invTexts=1/nTexts #to avoid weird values near 0 screwing things up \n",
    "            textWeights=textLen/textSum\n",
    "\n",
    "            textEarly=float(textDays[int(np.floor(nTexts*0.75))])\n",
    "            textMid=float(textDays[int(np.floor(nTexts*0.5))])\n",
    "            textLate=float(textDays[int(np.floor(nTexts*0.25))])\n",
    "\n",
    "            weightedSent=np.sum(textSent*textWeights) #sentiment weighted by frequency\n",
    "            scaledSent=(weightedSent+1)/2\n",
    "            sentRat=(scaledSent+invTexts)/(1-scaledSent+invTexts)\n",
    "            logSentRatio=np.log(sentRat) #for regression\n",
    "\n",
    "            textComplexity=np.mean(nSylls/textLen)# average ratio of syllables-by-length\n",
    "            meanTextLength=np.mean(textLen)\n",
    "            \n",
    "            commit_length = textEarly - textLate\n",
    "            if commit_length < 0:\n",
    "                commit_length = 0\n",
    "            \n",
    "            # positive vs negative\n",
    "            get_down = int(value['getDown'].replace(',', ''))\n",
    "            get_up = int(value['getUp'].replace(',', ''))\n",
    "            give_down = int(value['giveDown'].replace(',', ''))\n",
    "            give_up = int(value['giveUp'].replace(',', ''))\n",
    "            value['pos_get'] = np.log((get_up + 1.) / (get_down + 1.))\n",
    "            value['pos_give'] = np.log((give_up + 1.) / (give_down + 1.))\n",
    "                \n",
    "            # persistence\n",
    "            value['commitLength'] = np.log(commit_length + 1.)\n",
    "            # higher values of text_persist should mean more consistent, or increased participation over time\n",
    "            time_num = textEarly - textMid\n",
    "            if time_num < 0:\n",
    "                time_num = 0\n",
    "            time_denom = textEarly - textLate\n",
    "            if time_denom < 0:\n",
    "                time_denom = 0\n",
    "            value['textPersist'] = np.log((time_num + 1.) / (time_denom + 1.))\n",
    "            value['active'] = textDays[(len(textDays) -1)]\n",
    "\n",
    "            # give vs get\n",
    "            answers = int(value['nAnswers'].replace(',', ''))\n",
    "            questions = int(value['nPosts'].replace(',', ''))\n",
    "            comments = int(value['nComments'].replace(',', ''))\n",
    "            value['asks_vs_answers'] = np.log((questions + 1.) / (answers + 1.))\n",
    "            give_votes = give_up + give_down\n",
    "            get_votes = get_up + get_down\n",
    "            value['give_vs_get_votes'] = np.log((give_votes + 1.) / (get_votes + 1.))\n",
    "            \n",
    "            # productivity\n",
    "            writs = answers + questions + comments\n",
    "            value['scaled_writs'] = np.log((writs + 1.) / (commit_length + 1.0)) # writs: total g2g contributions\n",
    "            value['scaled_texts'] = np.log((nTexts + 1.) / (commit_length + 1.0)) # texts: g2g contributions I counted.\n",
    "            value['scaled_thanks'] = np.log((float(value['thanks'].replace(',', '')) + 1.) / (commit_length + 1.0))\n",
    "            value['log_contributions'] = np.log(value['contributions'] + 1.)\n",
    "            value['scaled_contributions'] = np.log((value['contributions'] + 1.) / (commit_length + 1.0))\n",
    "            value['logSentRatio'] = logSentRatio\n",
    "            value['textComplexity'] = textComplexity\n",
    "            value['meanTextLength']= meanTextLength\n",
    "\n",
    "        pdData=pd.DataFrame.from_dict(data, orient='index', )\n",
    "        pdData.to_csv('userData2.csv')   \n",
    "        return pdData\n",
    "    \n",
    "data = G2GDat('userData_trans.txt', 'questionData.txt')\n",
    "data.calcEvokedFeelings()\n",
    "user_dat = data.convertG2Gcsv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, for the Q&A board, and the site as a whole collected covers several major domains:\n",
    "\n",
    "* __Productivity__ How much did a user contribute? For how long?\n",
    "    * ```commitLength``` : how long (days) was their active period (defined as days between first and third quartiles of posts)?\n",
    "    * ```textPersist``` : how many contributions do they make in the latter portion of their active period relative to the first? \n",
    "    * ```scaled_writs``` : rate of production of questions, answers, comments (G2G).\n",
    "    * ```log_contributions``` : the overall log number of contributions made.\n",
    "    * ```scaled_contributions``` : how much genealogical work did they do, scaled by the length of their tenure?\n",
    "* __Positivity__ How positive was a user, and how much positivity did they elicit?\n",
    "    * ```logSentRatio``` : how positive are a user's texts?\n",
    "    * ```pos_give``` : what ratio of upvotes does a user give?\n",
    "    * ```pos_get``` : what ratio of upvotes does a user get? \n",
    "    * ```trans_delt_sent``` : how much more positive is a focal user than the other people they're interacting with, across all the posts they've contributed to?\n",
    "    * ```trans_q_adjust``` : after subtracting a focal user's contribution, how positive is the sentiment of the posts they contribute to?\n",
    "* __Helping__ How much did a user demand of others, or offer assistance?\n",
    "    * ```asks_vs_answers``` : how many questions asked, relative to help offered.\n",
    "    * ```scaled_thanks``` : how many thanks did a user receive?\n",
    "    * ```give_vs_get_votes``` : how many questions and responses did they vote on, vs receiving votes?\n",
    "* __Sophistication__ How 'smart' was a user, judging by their texts?\n",
    "    * ```textComplexity``` : how many syllables are the words they use on average (divided by text length (characters).\n",
    "    * ```meanTextLength``` : how long (characters) was their mean text?\n",
    "    \n",
    "Note that 'scaled' means scaled by the duration of the user's active period (not the period since they opened the account). All proportions were logit transformed, and all counts and ratios were log transformed (after ensuring this was appropriate, given the empirical distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['start_date','commitLength','textPersist', 'scaled_writs', 'scaled_contributions', 'log_contributions',\n",
    "                    'logSentRatio',\n",
    "                   'pos_give', 'pos_get', 'trans_delt_sent', 'trans_q_adjust','asks_vs_answers', 'scaled_thanks', \n",
    "                   'give_vs_get_votes', 'textComplexity', 'meanTextLength']\n",
    "\n",
    "X = user_dat.loc[((user_dat['n_texts'] > 1) & (user_dat['contributions'] > 10)),colnames]\n",
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot 1\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "fig_list = ['scaled_contributions', 'trans_q_adjust', 'logSentRatio','textComplexity']\n",
    "fig_captions = ['contributions (scaled)', 'evoked positivity', 'positive sentiment (log)', 'text complexity']\n",
    "for i, fig in enumerate(fig_list):\n",
    "    print i\n",
    "    plt.subplot(2,2, (i+1))\n",
    "    plt.xlabel(fig_captions[i])\n",
    "    plt.hist(X[fig], bins=50, color = def_color)\n",
    "    plt.subplots_adjust(wspace = 0.3) \n",
    "    plt.subplots_adjust(hspace = 0.5) \n",
    "    if i == 3:\n",
    "        plt.xticks(np.arange(0.05, 0.55, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot 2\n",
    "colnames = ['start_date','commitLength','textPersist', 'scaled_writs', 'scaled_contributions', 'log_contributions',\n",
    "                    'logSentRatio',\n",
    "                   'pos_give', 'pos_get', 'trans_delt_sent', 'trans_q_adjust','asks_vs_answers', 'scaled_thanks', \n",
    "                   'give_vs_get_votes', 'textComplexity', 'meanTextLength']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "def_color = sns.color_palette(\"Blues_d\")[2]\n",
    "ax = sns.regplot(x='asks_vs_answers', y='scaled_contributions', data=X, order = 1, ax = axes[0,0], color =  def_color)\n",
    "ax.set(xlabel='asks vs answers', ylabel='scaled contributions')\n",
    "ax = sns.regplot(x='logSentRatio', y='scaled_contributions', data=X, order = 1, ax = axes[0,1], color =  def_color)\n",
    "ax.set(xlabel='sentiment ratio (log)', ylabel='scaled contributions')\n",
    "ax = sns.regplot(x='give_vs_get_votes', y='scaled_contributions', data=X, order = 1, ax = axes[1,0], color =  def_color)\n",
    "ax.set(xlabel='give vs get votes', ylabel='scaled contributions')\n",
    "ax = sns.regplot(x=np.log(X['meanTextLength']), y=X['scaled_contributions'], order = 1, ax = axes[1,1], color =  def_color)\n",
    "ax.set(xlabel='mean text length', ylabel='scaled contributions')\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5) \n",
    "plt.subplots_adjust(hspace = 0.5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline for productivity\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "colnames2 = ['textPersist', 'scaled_writs', 'logSentRatio','pos_give', 'pos_get', \n",
    "             'trans_delt_sent', 'trans_q_adjust','asks_vs_answers', 'scaled_thanks', \n",
    "             'give_vs_get_votes', 'textComplexity', 'meanTextLength']\n",
    "\n",
    "#X = user_dat.loc[((user_dat['n_texts'] > 1) & (user_dat['contributions'] > 10)),colnames]\n",
    "scale = StandardScaler()\n",
    "X2 = X.loc[(X['start_date'] > 700), colnames2]\n",
    "scaled_contributions = np.array(X.loc[(X['start_date'] > 700), 'scaled_contributions'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "X2, scaled_contributions, test_size=0.3, random_state=42)\n",
    "\n",
    "production_pipeline = Pipeline([\n",
    "    ('rescale', StandardScaler()),\n",
    "    ('pca', PCA(12)),\n",
    "    ('random_forest', ensemble.RandomForestRegressor(n_estimators = 1000, min_samples_split = 10))\n",
    "    ])\n",
    "\n",
    "production_pipeline.fit(X_train, y_train)\n",
    "print production_pipeline.score(X_test, y_test)\n",
    "\n",
    "pd.DataFrame(production_pipeline.named_steps['pca'].components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GridSearchCV to optimize pipeline\n",
    "dims_grid = {'pca__n_components':np.array(range(1,13)),}\n",
    "\n",
    "grid = GridSearchCV(estimator=production_pipeline, param_grid=dims_grid)\n",
    "grid_result=grid.fit(X2, log_contributions)\n",
    "\n",
    "print grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnostic plot 3\n",
    "colnames = ['start_date','commitLength','textPersist', 'scaled_writs', 'scaled_contributions', 'commitLength',\n",
    "                    'logSentRatio',\n",
    "                   'pos_give', 'pos_get', 'trans_delt_sent', 'trans_q_adjust','asks_vs_answers', 'scaled_thanks', \n",
    "                   'give_vs_get_votes', 'textComplexity', 'meanTextLength']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "def_color = sns.color_palette(\"Blues_d\")[2]\n",
    "ax = sns.regplot(x='asks_vs_answers', y='trans_q_adjust', data=X, order = 1, ax = axes[0,0], color =  def_color)\n",
    "ax.set(xlabel='asks vs answers', ylabel='evoked positivity')\n",
    "ax = sns.regplot(x='scaled_contributions', y='trans_q_adjust', data=X, order = 1, ax = axes[0,1], color =  def_color)\n",
    "ax.set(xlabel='contributions (scaled)', ylabel='evoked positivity')\n",
    "ax = sns.regplot(x='logSentRatio', y='trans_q_adjust', data=X, order = 1, ax = axes[1,0], color =  def_color)\n",
    "ax.set(xlabel='positive sentiment (log)', ylabel='evoked positivity')\n",
    "ax = sns.regplot(x='textComplexity', y=X['trans_q_adjust'], data=X, order = 1, ax = axes[1,1], color =  def_color)\n",
    "ax.set(xlabel='text complexity', ylabel='evoked positivity')\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5) \n",
    "plt.subplots_adjust(hspace = 0.5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline for evoked positivity\n",
    "colnames3 = ['scaled_contributions','textPersist', 'scaled_writs', 'logSentRatio','pos_give', 'pos_get', \n",
    "             'trans_delt_sent','asks_vs_answers', 'scaled_thanks', \n",
    "             'give_vs_get_votes', 'textComplexity', 'meanTextLength']\n",
    "\n",
    "#X = user_dat.loc[((user_dat['n_texts'] > 1) & (user_dat['contributions'] > 10)),colnames]\n",
    "scale = StandardScaler()\n",
    "X3 = X.loc[(X['start_date'] > 700), colnames3]\n",
    "trans_q_adjust = np.array(X.loc[(X['start_date'] > 700), 'trans_q_adjust'])\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "X3, trans_q_adjust, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline_sentiment = Pipeline([\n",
    "    ('rescale', StandardScaler()),\n",
    "    ('pca', PCA(11)),\n",
    "    #('linear', linear_model.LinearRegression())\n",
    "    ('random_forest', ensemble.RandomForestRegressor(n_estimators = 1000, min_samples_split = 10))\n",
    "    #('ridge', linear_model.Ridge(alpha=1.0))\n",
    "    ])\n",
    "\n",
    "pipeline_sentiment.fit(X_train, y_train)\n",
    "print pipeline_sentiment.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dims_grid = {'pca__n_components':np.array(range(1,13)),'ridge__alpha':np.logspace(-4., 0, 20)}\n",
    "dims_grid = {'pca__n_components':np.array(range(1,13)),}\n",
    "\n",
    "grid = GridSearchCV(estimator=pipeline_sentiment, param_grid=dims_grid)\n",
    "grid_result=grid.fit(X3, trans_q_adjust)\n",
    "\n",
    "print grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.55526825e-02,  1.31339884e-01, -4.10111307e-02, -7.42468723e-05,\n",
       "        3.88204958e-02, -5.00563585e-02, -8.55702074e-03, -3.25474439e-02,\n",
       "        1.04663282e-01, -7.74811122e-03,  9.39746629e-03,  5.14963696e-02])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To examine the contents of the pipeline\n",
    "pd.DataFrame(pipeline_sentiment.named_steps['pca'].components_.T)\n",
    "pipeline_sentiment.named_steps['linear'].coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
